{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8f164c-565b-40b2-8a31-7faa390f4815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ea27386-076e-4670-aafa-be499bcb01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self, imageFolderDataset, transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "        should_get_same_class = random.randint(0, 1)\n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] == img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] != img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        img0 = img0.convert(\"RGB\")\n",
    "        img1 = img1.convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        return img0, img1, torch.from_numpy(np.array([int(img0_tuple[1] != img1_tuple[1])], dtype=np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf39a8a-256b-4271-b0e1-ac516bf2e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        weights = ResNet50_Weights.DEFAULT\n",
    "        self.backbone = resnet50(weights=weights)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the last fully connected layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2048, 500),  # Change to 2048 for resnet50\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(500, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 5)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.backbone(x)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d201a9-c3fd-42e6-8031-5b1d699bf247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee27473-55e7-40b8-8e57-306b44e36fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_siamese_network():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root='siamese-datasets/datasets/train', transform=transform)\n",
    "    siamese_dataset = SiameseNetworkDataset(imageFolderDataset=dataset, transform=transform)\n",
    "    train_loader = DataLoader(siamese_dataset, shuffle=True, num_workers=4, batch_size=4)\n",
    "\n",
    "    model = SiameseNetwork().cuda()\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "    num_epochs = 200\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            img0, img1, label = data\n",
    "            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = model(img0, img1)\n",
    "            loss_contrastive = criterion(output1, output2, label)\n",
    "            loss_contrastive.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss_contrastive.item()\n",
    "            euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "            predicted = (euclidean_distance > 1.0).float()\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}, Iter {i}, Loss: {loss_contrastive.item()}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "\n",
    "        train_loss.append(epoch_loss)\n",
    "        train_accuracy.append(epoch_accuracy)\n",
    "\n",
    "        # Save the model checkpoint\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.makedirs('checkpoints')\n",
    "        torch.save(model.state_dict(), f'checkpoints/siamese_epoch_{epoch+1}.pth')\n",
    "\n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), 'siamese_network.pth')\n",
    "\n",
    "    # Plot loss and accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs + 1), train_loss, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_siamese_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc096039-4fd0-4b10-9c3f-826cc8e598ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "def test_siamese_network(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            img0, img1, label = data\n",
    "            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "            output1, output2 = model(img0, img1)\n",
    "            euclidean_distance = nn.functional.pairwise_distance(output1, output2)\n",
    "            predicted = (euclidean_distance > 1.0).float()\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Chuẩn bị phép biến đổi và dữ liệu kiểm tra\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    test_dataset = datasets.ImageFolder(root='siamese-datasets/datasets/test', transform=transform)\n",
    "    siamese_test_dataset = SiameseNetworkDataset(imageFolderDataset=test_dataset, transform=transform)\n",
    "    test_loader = DataLoader(siamese_test_dataset, shuffle=False, num_workers=8, batch_size=2)\n",
    "\n",
    "    # Tải mô hình đã huấn luyện\n",
    "    model = SiameseNetwork().cuda()\n",
    "    model.load_state_dict(torch.load('siamese_network.pth'))\n",
    "\n",
    "    # Kiểm tra mô hình\n",
    "    test_siamese_network(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bdeb3-db2a-40f7-bfb2-d2195df58ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "# Hàm tải hình ảnh và chuyển đổi sang dạng Tensor\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Nếu hình ảnh có 4 channels (RGBA), chuyển đổi thành 3 channels (RGB)\n",
    "    if image.mode == 'RGBA':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    # Chuyển đổi hình ảnh thành dạng Tensor và chuẩn hóa\n",
    "    loader = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = loader(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# Tải mô hình đã được huấn luyện\n",
    "model = SiameseNetwork()\n",
    "model.load_state_dict(torch.load(\"siamese_network.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Hàm để đánh giá sự tương đồng giữa hai hình ảnh\n",
    "def evaluate_similarity(image_path1, image_path2):\n",
    "    image1 = load_image(image_path1)\n",
    "    image2 = load_image(image_path2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image1, image2)\n",
    "    \n",
    "    # Lấy phần tử đầu tiên từ tuple (giả sử chỉ có một tensor trong tuple)\n",
    "    tensor_output = output[0]\n",
    "    \n",
    "    # Kiểm tra kích thước của tensor_output\n",
    "    if isinstance(tensor_output, torch.Tensor) and tensor_output.numel() == 1:\n",
    "        similarity_score = tensor_output.item()\n",
    "    else:\n",
    "        # Xử lý trường hợp kích thước tensor_output không phải là 1\n",
    "        # Ví dụ: tính trung bình của các phần tử trong tensor_output\n",
    "        similarity_score = torch.mean(tensor_output).item()\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "# Ví dụ sử dụng hàm đánh giá\n",
    "image1_path = \"siamese-datasets/datasets/test/normal/normal (10).png\"\n",
    "image2_path = \"siamese-datasets/datasets/test/unnormal/unnormal (27).png\"\n",
    "similarity_score = evaluate_similarity(image1_path, image2_path)\n",
    "print(\"Similarity Score:\", similarity_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
